---
title: "Modeling"
author: "Matthew Ross"
date: "2024-11-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(dplyr)
library(tidyr)
library(mgcv)
library(tidygeocoder)
```

```{r}
d <- read.csv("intermediate.csv")

unique_towns <- d %>%
  distinct(Town) %>%
  filter(!is.na(Town)) %>%
  mutate(full_address = paste0(Town, ", California"))

# Geocode towns to get latitude and longitude
town_coords <- unique_towns %>%
  geocode(address = full_address, method = "osm") %>%
  rename(lat.census.town = lat, lon.census.town = long)

# Merge geocoded coordinates back into the main dataframe
d <- d %>%
  left_join(town_coords, by = "Town")
```

```{r}
# Load required libraries
library(dplyr)
library(lubridate)
library(glmnet)
library(INLA)

d %>% filter(Year == "2010")

e <- read.csv('merged_final_new.csv')
e %>% filter(Date_Year == "2010")

# Step 1: Aggregate Data to 6-Month Periods

numeric_columns <- d %>%
  select(starts_with("Estimate.")) %>%
  select(where(is.numeric)) %>%
  colnames()
d %>%
  filter(Town == "Alameda") %>%
  arrange(Year_Month)

d_agg <- d %>%
  mutate(Year_Month = as.Date(paste0(Year_Month, "-01")),
         Period = floor_date(Year_Month, unit = "6 months")) %>%
  group_by(Town, Period) %>%
  summarise(
    # Deal metrics
    Deal_Volume = n(),  # Count total deals per group
    Avg_Deal_Size = mean(Deal.Size.Usd.Mn., na.rm = TRUE),  # Average deal size
    Total_Size_Sq_Ft = mean(Total.Size.Sq.Ft., na.rm = TRUE),  # Average size in sq ft
    Total_Deal_Size_Usd_Mn = sum(Deal.Size.Usd.Mn., na.rm = TRUE),  # Total deal size

    # Monthly predictors
    Fed_Rate = mean(Fed_Rate, na.rm = TRUE),
    Unemployment_Rate = mean(Unemployment_Rate, na.rm = TRUE),
    HomeValue = mean(HomeValue, na.rm = TRUE),

    # Yearly predictors: Only numeric "Estimate." columns
    across(all_of(numeric_columns), ~ mean(., na.rm = TRUE), .names = "{.col}"),

    # Categorical predictors
    Opportunity_Zone = first(Opportunity_Zone),

    # Geographic information
    lat.census.town = first(lat.census.town),
    lon.census.town = first(lon.census.town),
    .groups = "drop"
  )

d_agg
# Step 2: Prepare Data for LASSO
# Convert categorical variables to factors
d <- d %>%
  mutate(Opportunity_Zone = as.factor(Opportunity_Zone))

# Select predictors and response variable
X <- model.matrix(
  Deal_Volume ~ . - Town - Period - lat.census.town - lon.census.town - 1,
  data = d
)
y <- d$Deal_Volume

# Step 3: Perform LASSO Regression
lasso_model <- cv.glmnet(X, y, alpha = 1, family = "poisson")  # LASSO for variable selection
lasso_coefficients <- coef(lasso_model, s = "lambda.min")  # Coefficients at optimal lambda

# Extract selected predictors
selected_predictors <- rownames(lasso_coefficients)[lasso_coefficients != 0]
selected_predictors <- selected_predictors[selected_predictors != "(Intercept)"]

# Step 4: Spatio-Temporal Model Using INLA
# Define spatial mesh
coords <- d %>%
  select(lon.census.town, lat.census.town) %>%
  distinct() %>%
  as.matrix()

mesh <- inla.mesh.2d(loc = coords, max.edge = c(0.1, 0.5), cutoff = 0.05)

# Define spatial field
spde <- inla.spde2.pcmatern(
  mesh = mesh,
  alpha = 2,  # Smoothness parameter
  prior.range = c(0.1, 0.5),  # Prior for spatial range
  prior.sigma = c(1, 0.1)     # Prior for marginal standard deviation
)

# Build INLA stack for spatio-temporal model
A <- inla.spde.make.A(mesh, loc = coords)
spatial_index <- inla.spde.make.index("spatial.field", n.spde = spde$n.spde)

stack <- inla.stack(
  data = list(y = d$Deal_Volume),
  A = list(A, 1),
  effects = list(
    spatial.field = spatial_index,
    data = d %>% select(all_of(selected_predictors))
  )
)

# Define the spatio-temporal model formula
formula <- y ~ 
  f(spatial.field, model = spde) +  # Continuous spatial field
  f(Period, model = "ar1") +        # Temporal autocorrelation
  .                                 # Include selected predictors dynamically

# Fit the INLA model
result <- inla(
  formula,
  data = inla.stack.data(stack),
  family = "poisson",  # Assuming count data for deal volume
  control.predictor = list(A = inla.stack.A(stack), compute = TRUE),
  control.compute = list(dic = TRUE, waic = TRUE)  # Compute model metrics
)

# Display model summary
summary(result)

# Step 5: Visualizations
# Temporal Trends
library(ggplot2)
ggplot(d, aes(x = Period, y = Deal_Volume, group = Town, color = Opportunity_Zone)) +
  geom_line() +
  labs(title = "Deal Volume Over Time by Town",
       x = "6-Month Period",
       y = "Total Deals",
       color = "Opportunity Zone") +
  theme_minimal()

# Spatial Trends
ggplot(d, aes(x = lon.census.town, y = lat.census.town, size = Deal_Volume, color = Unemployment_Rate)) +
  geom_point(alpha = 0.7) +
  labs(title = "Spatial Distribution of Deal Volume",
       x = "Longitude",
       y = "Latitude",
       size = "Total Deals",
       color = "Unemployment Rate") +
  theme_minimal()
d

e %>% filter(Date_Year == "2010")
```


