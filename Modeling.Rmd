---
title: "Modeling"
author: "Matthew Ross"
date: "2024-11-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(dplyr)
library(tidyr)
library(mgcv)
library(tidygeocoder)
```

```{r}
d <- read.csv("intermediate_for_modeling.csv")

unique_towns <- d %>%
  distinct(Town) %>%
  filter(!is.na(Town)) %>%
  mutate(full_address = paste0(Town, ", California"))

# Geocode towns to get latitude and longitude
town_coords <- unique_towns %>%
  geocode(address = full_address, method = "osm") %>%
  rename(lat.census.town = lat, lon.census.town = long)

# Merge geocoded coordinates back into the main dataframe
d <- d %>%
  left_join(town_coords, by = "Town")

d_new <- d
predictor_data <- read.csv("predictor_data.csv")
```

```{r}
# Load required libraries
library(dplyr)
library(tidyr)
library(lubridate)
library(zoo)
library(geosphere)

# Step 1: Ensure numeric columns in d_new are valid
d_new <- d_new %>%
  mutate(across(starts_with("Estimate."), ~ as.numeric(.), .names = "{.col}"))  # Convert non-numeric to NA

# Step 2: Ensure Year_Month is in Date format and create 6-month periods in d_new
d_new <- d_new %>%
  mutate(
    Year_Month = as.Date(paste0(Year_Month, "-01")),
    Period = floor_date(Year_Month, unit = "6 months")
  )

# Step 3: Ensure Year_Month and Period in predictor_data and validate numeric columns
predictor_data <- predictor_data %>%
  mutate(
    Year_Month = as.Date(paste0(Year_Month, "-01")),
    Period = floor_date(Year_Month, unit = "6 months")
  ) %>%
  mutate(across(
    starts_with("Estimate.") | matches("Opportunity_Zone"),
    ~ as.numeric(.),
    .names = "{.col}"
  ))  # Convert non-numeric to NA

d_aggregated <- d_new %>%
  mutate(
    Asset_Class = case_when(
      Primary.Asset.Type %in% c("Residential", "Industrial", "Office", "Retail") ~ Primary.Asset.Type,
      Primary.Asset.Type %in% c("Niche", "Mixed Use", "Land", "Hotel") ~ "Other",
      TRUE ~ "Unknown"
    )
  ) %>%
  group_by(Town, Period) %>%
  summarise(
    Deal_Volume = n(),
    Avg_Deal_Size = ifelse(Deal_Volume > 0, mean(Deal.Size.Usd.Mn., na.rm = TRUE), NA),
    Total_Size_Sq_Ft = ifelse(Deal_Volume > 0, mean(Total.Size.Sq.Ft., na.rm = TRUE), NA),
    Fed_Rate = mean(Fed_Rate, na.rm = TRUE),
    Unemployment_Rate = mean(Unemployment_Rate, na.rm = TRUE),
    HomeValue = mean(HomeValue, na.rm = TRUE),
    across(starts_with("Estimate."), ~ mean(., na.rm = TRUE), .names = "{.col}"),
    Opportunity_Zone = first(Opportunity_Zone),
    lat.census.town = first(lat.census.town),
    lon.census.town = first(lon.census.town),
    Residential_Percentage = sum(Asset_Class == "Residential") / Deal_Volume * 100,
    Industrial_Percentage = sum(Asset_Class == "Industrial") / Deal_Volume * 100,
    Office_Percentage = sum(Asset_Class == "Office") / Deal_Volume * 100,
    Retail_Percentage = sum(Asset_Class == "Retail") / Deal_Volume * 100,
    Other_Percentage = sum(Asset_Class == "Other") / Deal_Volume * 100,
    .groups = "drop"
  )

# Step 5: Fill in missing periods for each Town
full_grid <- expand.grid(
  Town = unique(d_new$Town),
  Period = seq(min(d_new$Period), max(d_new$Period), by = "6 months")
)

d_aggregated <- full_grid %>%
  left_join(d_aggregated, by = c("Town", "Period"))

# Step 6: Set percentages and metrics to 0 for periods with no deals
d_aggregated <- d_aggregated %>%
  mutate(
    Deal_Volume = ifelse(is.na(Deal_Volume), 0, Deal_Volume),
    Avg_Deal_Size = ifelse(Deal_Volume == 0, 0, Avg_Deal_Size),
    Total_Size_Sq_Ft = ifelse(Deal_Volume == 0, 0, Total_Size_Sq_Ft),
    Residential_Percentage = ifelse(Deal_Volume == 0, 0, Residential_Percentage),
    Industrial_Percentage = ifelse(Deal_Volume == 0, 0, Industrial_Percentage),
    Office_Percentage = ifelse(Deal_Volume == 0, 0, Office_Percentage),
    Retail_Percentage = ifelse(Deal_Volume == 0, 0, Retail_Percentage),
    Other_Percentage = ifelse(Deal_Volume == 0, 0, Other_Percentage)
  )
# Step 7: Perform row-wise updates
d_aggregated <- d_aggregated %>%
  rowwise() %>%
  mutate(
    Fed_Rate = ifelse(
      Deal_Volume == 0,
      mean(predictor_data$Fed_Rate[
        predictor_data$Period == Period
      ], na.rm = TRUE),
      Fed_Rate
    ),
    Unemployment_Rate = ifelse(
      Deal_Volume == 0,
      mean(predictor_data$Unemployment_Rate[
        predictor_data$Period == Period
      ], na.rm = TRUE),
      Unemployment_Rate
    ),
    HomeValue = ifelse(
      Deal_Volume == 0,
      mean(predictor_data$HomeValue[
        predictor_data$Period == Period
      ], na.rm = TRUE),
      HomeValue
    ),
    Opportunity_Zone = ifelse(
      Deal_Volume == 0,
      mean(predictor_data$Opportunity_Zone[
        predictor_data$Town == Town & predictor_data$Period == Period
      ], na.rm = TRUE),
      Opportunity_Zone
    ),
    across(
      starts_with("Estimate."),
      ~ ifelse(
        Deal_Volume == 0,
        mean(predictor_data[[cur_column()]][
          predictor_data$Town == Town & predictor_data$Period == Period
        ], na.rm = TRUE),
        .
      )
    ),
    lat.census.town = first(d_new$lat.census.town[d_new$Town == Town]),
    lon.census.town = first(d_new$lon.census.town[d_new$Town == Town])
  ) %>%
  ungroup()

# Step 8: Forward-backward fill for HomeValue and Estimate.* columns
d_aggregated <- d_aggregated %>%
  group_by(Town) %>%
  mutate(
    HomeValue = ifelse(
      is.na(HomeValue),
      zoo::na.locf(HomeValue, na.rm = FALSE, fromLast = FALSE),
      HomeValue
    ),
    HomeValue = ifelse(
      is.na(HomeValue),
      zoo::na.locf(HomeValue, na.rm = FALSE, fromLast = TRUE),
      HomeValue
    ),
    across(
      starts_with("Estimate."),
      ~ ifelse(
        is.na(.),
        zoo::na.locf(.x, na.rm = FALSE, fromLast = FALSE),
        .
      )
    ),
    across(
      starts_with("Estimate."),
      ~ ifelse(
        is.na(.),
        zoo::na.locf(.x, na.rm = FALSE, fromLast = TRUE),
        .
      )
    )
  ) %>%
  ungroup()

# Step 9: Fill missing values from nearest town if a town has no data for HomeValue or Estimate.*
fill_from_nearest <- function(row, target_column) {
  if (!is.na(row[[target_column]])) {
    return(row[[target_column]])
  }
  
  current_town <- row$Town
  current_period <- row$Period
  current_lat <- row$lat.census.town
  current_lon <- row$lon.census.town
  
  valid_towns <- d_aggregated %>%
    filter(!is.na(!!sym(target_column)) & Period == current_period) %>%
    mutate(distance = distHaversine(cbind(lon.census.town, lat.census.town), 
                                    c(current_lon, current_lat))) %>%
    arrange(distance)
  
  if (nrow(valid_towns) > 0) {
    return(valid_towns[[target_column]][1])
  }
  
  return(NA)
}

# Apply nearest town logic
d_aggregated <- d_aggregated %>%
  rowwise() %>%
  mutate(
    HomeValue = ifelse(is.na(HomeValue), fill_from_nearest(cur_data(), "HomeValue"), HomeValue),
    across(
      starts_with("Estimate."),
      ~ ifelse(is.na(.), fill_from_nearest(cur_data(), cur_column()), .)
    )
  ) %>%
  ungroup()
```
```{r}
library(zoo)
library(geosphere)

# Forward-backward search for Avg_Deal_Size and Total_Size_Sq_Ft within each town
d_aggregated <- d_aggregated %>%
  group_by(Town) %>%
  mutate(
    Avg_Deal_Size = ifelse(
      is.na(Avg_Deal_Size),
      zoo::na.locf(Avg_Deal_Size, na.rm = FALSE, fromLast = FALSE),
      Avg_Deal_Size
    ),
    Avg_Deal_Size = ifelse(
      is.na(Avg_Deal_Size),
      zoo::na.locf(Avg_Deal_Size, na.rm = FALSE, fromLast = TRUE),
      Avg_Deal_Size
    ),
    Total_Size_Sq_Ft = ifelse(
      is.na(Total_Size_Sq_Ft),
      zoo::na.locf(Total_Size_Sq_Ft, na.rm = FALSE, fromLast = FALSE),
      Total_Size_Sq_Ft
    ),
    Total_Size_Sq_Ft = ifelse(
      is.na(Total_Size_Sq_Ft),
      zoo::na.locf(Total_Size_Sq_Ft, na.rm = FALSE, fromLast = TRUE),
      Total_Size_Sq_Ft
    )
  ) %>%
  ungroup()

# Define the function for nearest-town analysis
fill_from_nearest <- function(row, target_column) {
  if (!is.na(row[[target_column]])) {
    return(row[[target_column]])  # Return existing value if it's not NA
  }
  
  # Extract relevant information for the current row
  current_town <- row$Town
  current_period <- row$Period
  current_lat <- row$lat.census.town
  current_lon <- row$lon.census.town
  
  # Find the nearest town with valid data for the target column
  valid_towns <- d_aggregated %>%
    filter(!is.na(!!sym(target_column)) & Deal_Volume > 1 & Period == current_period) %>%
    mutate(distance = distHaversine(cbind(lon.census.town, lat.census.town), 
                                    c(current_lon, current_lat))) %>%
    arrange(distance)  # Sort by distance
  
  if (nrow(valid_towns) > 0) {
    return(valid_towns[[target_column]][1])  # Return the value from the nearest valid town
  }
  
  return(NA)  # Return NA if no valid data is found
}

# Apply nearest-town logic to Avg_Deal_Size and Total_Size_Sq_Ft
d_aggregated <- d_aggregated %>%
  rowwise() %>%
  mutate(
    Avg_Deal_Size = ifelse(is.na(Avg_Deal_Size), fill_from_nearest(cur_data(), "Avg_Deal_Size"), Avg_Deal_Size),
    Total_Size_Sq_Ft = ifelse(is.na(Total_Size_Sq_Ft), fill_from_nearest(cur_data(), "Total_Size_Sq_Ft"), Total_Size_Sq_Ft)
  ) %>%
  ungroup()

# saveRDS(d_aggregated, "data_for_modeling.rds")
```




```{r}
df_aggregated <- readRDS("data_for_modeling.rds")

library(INLA)
# Step 2: Prepare Data for LASSO
# Convert categorical variables to factors
numeric_predictors <- d_aggregated %>%
  select(Fed_Rate, Unemployment_Rate, HomeValue, all_of(numeric_columns)) %>%
  colnames()

# Apply normalization to numeric predictors
d_aggregated <- d_aggregated %>%
  mutate(across(all_of(numeric_predictors), scale, .names = "{.col}_scaled"))

# LASSO Regression (using normalized predictors)
X <- model.matrix(
  Deal_Volume ~ . - Town - Period - lat.census.town - lon.census.town - 1,
  data = d_aggregated %>%
    select(ends_with("_scaled"), Deal_Volume, Opportunity_Zone)
)
y <- d_aggregated$Deal_Volume
y <- d_aggregated$Deal_Volume

# Step 3: Perform LASSO Regression
lasso_model <- cv.glmnet(X, y, alpha = 1, family = "poisson")  # LASSO for variable selection
lasso_coefficients <- coef(lasso_model, s = "lambda.min")  # Coefficients at optimal lambda

# Extract selected predictors
selected_predictors <- rownames(lasso_coefficients)[lasso_coefficients != 0]
selected_predictors <- selected_predictors[selected_predictors != "(Intercept)"]

# Step 4: Spatio-Temporal Model Using INLA
# Define spatial mesh
coords <- d_aggregated %>%
  select(lon.census.town, lat.census.town) %>%
  distinct() %>%
  as.matrix()

mesh <- inla.mesh.2d(loc = coords, max.edge = c(0.1, 0.5), cutoff = 0.05)

# Define spatial field
spde <- inla.spde2.pcmatern(
  mesh = mesh,
  alpha = 2,  # Smoothness parameter
  prior.range = c(0.1, 0.5),  # Prior for spatial range
  prior.sigma = c(1, 0.1)     # Prior for marginal standard deviation
)

# Build INLA stack for spatio-temporal model
A <- inla.spde.make.A(mesh, loc = coords)
spatial_index <- inla.spde.make.index("spatial.field", n.spde = spde$n.spde)

stack <- inla.stack(
  data = list(y = d_aggregated$Deal_Volume),
  A = list(A, 1),
  effects = list(
    spatial.field = spatial_index,
    data = d_aggregated %>% select(all_of(selected_predictors))
  )
)

# Define the spatio-temporal model formula
formula <- y ~ 
  f(spatial.field, model = spde) +  # Continuous spatial field
  f(Period, model = "ar1") +        # Temporal autocorrelation
  .                                 # Include selected predictors dynamically

# Fit the INLA model
result <- inla(
  formula,
  data = inla.stack.data(stack),
  family = "poisson",  # Assuming count data for deal volume
  control.predictor = list(A = inla.stack.A(stack), compute = TRUE),
  control.compute = list(dic = TRUE, waic = TRUE)  # Compute model metrics
)

# Display model summary
summary(result)

# Step 5: Visualizations
# Temporal Trends
library(ggplot2)
ggplot(d_aggregated, aes(x = Period, y = Deal_Volume, group = Town, color = Opportunity_Zone)) +
  geom_line() +
  labs(title = "Deal Volume Over Time by Town",
       x = "6-Month Period",
       y = "Total Deals",
       color = "Opportunity Zone") +
  theme_minimal()

# Spatial Trends
ggplot(d_aggregated, aes(x = lon.census.town, y = lat.census.town, size = Deal_Volume, color = Unemployment_Rate)) +
  geom_point(alpha = 0.7) +
  labs(title = "Spatial Distribution of Deal Volume",
       x = "Longitude",
       y = "Latitude",
       size = "Total Deals",
       color = "Unemployment Rate") +
  theme_minimal()



```


